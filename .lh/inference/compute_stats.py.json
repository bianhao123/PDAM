{
    "sourceFile": "inference/compute_stats.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1674909779649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1674909790885,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,9 +33,9 @@\n         type_uid_list : list of id for nuclei type which the score should be calculated.\n                         Default to `None` means available nuclei type in GT.\n         exhaustive : Flag to indicate whether GT is exhaustively labelled\n                      for instance types\n-                     \n+\n     \"\"\"\n     file_list = glob.glob(pred_dir + \"*.mat\")\n     file_list.sort()  # ensure same order [1]\n \n@@ -81,12 +81,14 @@\n \n         # * Aggreate information\n         # get the offset as each index represent 1 independent instance\n         true_idx_offset = (\n-            true_idx_offset + true_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n+            true_idx_offset +\n+            true_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n         )\n         pred_idx_offset = (\n-            pred_idx_offset + pred_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n+            pred_idx_offset +\n+            pred_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n         )\n         true_inst_type_all.append(true_inst_type)\n         pred_inst_type_all.append(pred_inst_type)\n \n@@ -223,9 +225,8 @@\n         pred = remap_label(pred, by_size=False)\n         true = remap_label(true, by_size=False)\n         # plt.imshow(pred)\n         # plt.imshow(true)\n-        \n \n         pq_info = get_fast_pq(true, pred, match_iou=0.5)[0]\n         print(pq_info)\n         if np.array(pq_info).sum() == 0:\n@@ -265,14 +266,15 @@\n     parser.add_argument(\n         \"--pred_dir\", help=\"point to output dir\", nargs=\"?\", default=\"/data111/bianhao/code/zhangye/PDAM/inference/pannuke2tnbc\", const=\"\"\n     )\n     parser.add_argument(\n-        \"--true_dir\", help=\"point to ground truth dir\", nargs=\"?\", default=\"/data3/zhangye/Tissue-Image-Segmentation-master/data/consep/test\", const=\"\"\n+        \"--true_dir\", help=\"point to ground truth dir\", nargs=\"?\", default=\"/data111/bianhao/code/zhangye/PDAM/ZY_CVPR/tnbc/test\", const=\"\"\n     )\n     parser.add_argument(\"--dataset\",)\n     args = parser.parse_args()\n     args.dataset = \"CryoNuSeg\"\n \n     if args.mode == \"instance\":\n-        run_nuclei_inst_stat(args.pred_dir, args.true_dir, args.dataset, print_img_stats=False)\n+        run_nuclei_inst_stat(args.pred_dir, args.true_dir,\n+                             args.dataset, print_img_stats=False)\n     if args.mode == \"type\":\n         run_nuclei_type_stat(args.pred_dir, args.true_dir)\n"
                },
                {
                    "date": 1674909838125,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -269,9 +269,9 @@\n         \"--true_dir\", help=\"point to ground truth dir\", nargs=\"?\", default=\"/data111/bianhao/code/zhangye/PDAM/ZY_CVPR/tnbc/test\", const=\"\"\n     )\n     parser.add_argument(\"--dataset\",)\n     args = parser.parse_args()\n-    args.dataset = \"CryoNuSeg\"\n+    args.dataset = \"TNBC\"\n \n     if args.mode == \"instance\":\n         run_nuclei_inst_stat(args.pred_dir, args.true_dir, args.dataset, print_img_stats=False)\n     if args.mode == \"type\":\n"
                }
            ],
            "date": 1674909779649,
            "name": "Commit-0",
            "content": "import argparse\nimport glob\nimport os\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport scipy.io as sio\nimport matplotlib.pyplot as plt\n\nfrom metrics.stats_utils import (\n    get_dice_1,\n    get_fast_aji,\n    get_fast_aji_plus,\n    get_fast_dice_2,\n    get_fast_pq,\n    remap_label,\n    pair_coordinates\n)\n\n\ndef run_nuclei_type_stat(pred_dir, true_dir, type_uid_list=None, exhaustive=True):\n    \"\"\"GT must be exhaustively annotated for instance location (detection).\n\n    Args:\n        true_dir, pred_dir: Directory contains .mat annotation for each image. \n                            Each .mat must contain:\n                    --`inst_centroid`: Nx2, contains N instance centroid\n                                       of mass coordinates (X, Y)\n                    --`inst_type`    : Nx1: type of each instance at each index\n                    `inst_centroid` and `inst_type` must be aligned and each\n                    index must be associated to the same instance\n        type_uid_list : list of id for nuclei type which the score should be calculated.\n                        Default to `None` means available nuclei type in GT.\n        exhaustive : Flag to indicate whether GT is exhaustively labelled\n                     for instance types\n                     \n    \"\"\"\n    file_list = glob.glob(pred_dir + \"*.mat\")\n    file_list.sort()  # ensure same order [1]\n\n    paired_all = []  # unique matched index pair\n    unpaired_true_all = []  # the index must exist in `true_inst_type_all` and unique\n    unpaired_pred_all = []  # the index must exist in `pred_inst_type_all` and unique\n    true_inst_type_all = []  # each index is 1 independent data point\n    pred_inst_type_all = []  # each index is 1 independent data point\n    for file_idx, filename in enumerate(file_list[:]):\n        filename = os.path.basename(filename)\n        basename = filename.split(\".\")[0]\n\n        true_info = sio.loadmat(os.path.join(true_dir, basename + \".mat\"))\n        # dont squeeze, may be 1 instance exist\n        true_centroid = (true_info[\"inst_centroid\"]).astype(\"float32\")\n        true_inst_type = (true_info[\"inst_type\"]).astype(\"int32\")\n\n        if true_centroid.shape[0] != 0:\n            true_inst_type = true_inst_type[:, 0]\n        else:  # no instance at all\n            true_centroid = np.array([[0, 0]])\n            true_inst_type = np.array([0])\n\n        # * for converting the GT type in CoNSeP\n        # true_inst_type[(true_inst_type == 3) | (true_inst_type == 4)] = 3\n        # true_inst_type[(true_inst_type == 5) | (true_inst_type == 6) | (true_inst_type == 7)] = 4\n\n        pred_info = sio.loadmat(os.path.join(pred_dir, basename + \".mat\"))\n        # dont squeeze, may be 1 instance exist\n        pred_centroid = (pred_info[\"inst_centroid\"]).astype(\"float32\")\n        pred_inst_type = (pred_info[\"inst_type\"]).astype(\"int32\")\n\n        if pred_centroid.shape[0] != 0:\n            pred_inst_type = pred_inst_type[:, 0]\n        else:  # no instance at all\n            pred_centroid = np.array([[0, 0]])\n            pred_inst_type = np.array([0])\n\n        # ! if take longer than 1min for 1000 vs 1000 pairing, sthg is wrong with coord\n        paired, unpaired_true, unpaired_pred = pair_coordinates(\n            true_centroid, pred_centroid, 12\n        )\n\n        # * Aggreate information\n        # get the offset as each index represent 1 independent instance\n        true_idx_offset = (\n            true_idx_offset + true_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n        )\n        pred_idx_offset = (\n            pred_idx_offset + pred_inst_type_all[-1].shape[0] if file_idx != 0 else 0\n        )\n        true_inst_type_all.append(true_inst_type)\n        pred_inst_type_all.append(pred_inst_type)\n\n        # increment the pairing index statistic\n        if paired.shape[0] != 0:  # ! sanity\n            paired[:, 0] += true_idx_offset\n            paired[:, 1] += pred_idx_offset\n            paired_all.append(paired)\n\n        unpaired_true += true_idx_offset\n        unpaired_pred += pred_idx_offset\n        unpaired_true_all.append(unpaired_true)\n        unpaired_pred_all.append(unpaired_pred)\n\n    paired_all = np.concatenate(paired_all, axis=0)\n    unpaired_true_all = np.concatenate(unpaired_true_all, axis=0)\n    unpaired_pred_all = np.concatenate(unpaired_pred_all, axis=0)\n    true_inst_type_all = np.concatenate(true_inst_type_all, axis=0)\n    pred_inst_type_all = np.concatenate(pred_inst_type_all, axis=0)\n\n    paired_true_type = true_inst_type_all[paired_all[:, 0]]\n    paired_pred_type = pred_inst_type_all[paired_all[:, 1]]\n    unpaired_true_type = true_inst_type_all[unpaired_true_all]\n    unpaired_pred_type = pred_inst_type_all[unpaired_pred_all]\n\n    ###\n    def _f1_type(paired_true, paired_pred, unpaired_true, unpaired_pred, type_id, w):\n        type_samples = (paired_true == type_id) | (paired_pred == type_id)\n\n        paired_true = paired_true[type_samples]\n        paired_pred = paired_pred[type_samples]\n\n        tp_dt = ((paired_true == type_id) & (paired_pred == type_id)).sum()\n        tn_dt = ((paired_true != type_id) & (paired_pred != type_id)).sum()\n        fp_dt = ((paired_true != type_id) & (paired_pred == type_id)).sum()\n        fn_dt = ((paired_true == type_id) & (paired_pred != type_id)).sum()\n\n        if not exhaustive:\n            ignore = (paired_true == -1).sum()\n            fp_dt -= ignore\n\n        fp_d = (unpaired_pred == type_id).sum()\n        fn_d = (unpaired_true == type_id).sum()\n\n        f1_type = (2 * (tp_dt + tn_dt)) / (\n            2 * (tp_dt + tn_dt)\n            + w[0] * fp_dt\n            + w[1] * fn_dt\n            + w[2] * fp_d\n            + w[3] * fn_d\n        )\n        return f1_type\n\n    # overall\n    # * quite meaningless for not exhaustive annotated dataset\n    w = [1, 1]\n    tp_d = paired_pred_type.shape[0]\n    fp_d = unpaired_pred_type.shape[0]\n    fn_d = unpaired_true_type.shape[0]\n\n    tp_tn_dt = (paired_pred_type == paired_true_type).sum()\n    fp_fn_dt = (paired_pred_type != paired_true_type).sum()\n\n    if not exhaustive:\n        ignore = (paired_true_type == -1).sum()\n        fp_fn_dt -= ignore\n\n    acc_type = tp_tn_dt / (tp_tn_dt + fp_fn_dt)\n    f1_d = 2 * tp_d / (2 * tp_d + w[0] * fp_d + w[1] * fn_d)\n\n    w = [2, 2, 1, 1]\n\n    if type_uid_list is None:\n        type_uid_list = np.unique(true_inst_type_all).tolist()\n\n    results_list = [f1_d, acc_type]\n    for type_uid in type_uid_list:\n        f1_type = _f1_type(\n            paired_true_type,\n            paired_pred_type,\n            unpaired_true_type,\n            unpaired_pred_type,\n            type_uid,\n            w,\n        )\n        results_list.append(f1_type)\n\n    np.set_printoptions(formatter={\"float\": \"{: 0.5f}\".format})\n    print(np.array(results_list))\n    return\n\n\ndef run_nuclei_inst_stat(pred_dir, true_dir, dataset, print_img_stats=False, ext=\".mat\"):\n    # print stats of each image\n    # print(pred_dir)\n\n    file_list = glob.glob(\"%s/*%s\" % (pred_dir, ext))\n    file_list.sort()  # ensure same order\n    # print(file_list)\n\n    metrics = [[], [], [], [], [], []]\n    for filename in file_list[:]:\n        filename = os.path.basename(filename)\n        basename = filename.split(\".\")[0]\n        print(basename)\n\n        if dataset == \"Lizard\":\n            true = np.load(os.path.join(true_dir, basename + \"_instance.npy\"))\n            # if int(basename) <= 3983:\n            #     continue\n\n        if dataset == \"CryoNuSeg\":\n            # true = cv2.imread(os.path.join(true_dir, basename + \"_instance_colorized.png\"),cv2.IMREAD_GRAYSCALE)\n            # true = true.astype(\"int32\")\n            # print(np.unique(true))\n            true = np.load(os.path.join(true_dir, basename + \"_instance.npy\"))\n        elif dataset == \"TNBC\":\n            true = np.load(os.path.join(true_dir, basename + \"_instance.npy\"))\n            # basename_ = str(int(basename)-387)\n            # true = cv2.imread(os.path.join(true_dir, basename + \".png\"),cv2.IMREAD_GRAYSCALE)\n            # true = true.astype(\"int32\")\n\n        else:\n            true = np.load(os.path.join(true_dir, basename + \"_instance.npy\"))\n            # true = sio.loadmat(os.path.join(true_dir, basename + \".mat\"))\n            # true = (true[\"inst_map\"]).astype(\"int32\")\n\n        pred = sio.loadmat(os.path.join(pred_dir, basename + \".mat\"))\n        pred = (pred[\"inst_map\"]).astype(\"int32\")\n        # pred = cv2.imread(f\"{pred_dir}/{basename}_seg_colored.png\", cv2.IMREAD_GRAYSCALE)\n        # print(pred.shape)\n\n        # to ensure that the instance numbering is contiguous\n        pred = remap_label(pred, by_size=False)\n        true = remap_label(true, by_size=False)\n        # plt.imshow(pred)\n        # plt.imshow(true)\n        \n\n        pq_info = get_fast_pq(true, pred, match_iou=0.5)[0]\n        print(pq_info)\n        if np.array(pq_info).sum() == 0:\n            continue\n        metrics[0].append(get_dice_1(true, pred))\n        metrics[1].append(get_fast_aji(true, pred))\n        metrics[2].append(pq_info[0])  # dq\n        metrics[3].append(pq_info[1])  # sq\n        metrics[4].append(pq_info[2])  # pq\n        metrics[5].append(get_fast_aji_plus(true, pred))\n\n        if print_img_stats:\n            print(basename, end=\"\\t\")\n            for scores in metrics:\n                print(\"%f \" % scores[-1], end=\"  \")\n            print()\n    ####\n    metrics = np.array(metrics)\n    metrics_avg = np.mean(metrics, axis=-1)\n    np.set_printoptions(formatter={\"float\": \"{: 0.5f}\".format})\n    print(metrics_avg)\n    metrics_avg = list(metrics_avg)\n    return metrics\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        help=\"mode to run the measurement,\"\n        \"`type` for nuclei instance type classification or\"\n        \"`instance` for nuclei instance segmentation\",\n        nargs=\"?\",\n        default=\"instance\",\n        const=\"instance\",\n    )\n    parser.add_argument(\n        \"--pred_dir\", help=\"point to output dir\", nargs=\"?\", default=\"/data111/bianhao/code/zhangye/PDAM/inference/pannuke2tnbc\", const=\"\"\n    )\n    parser.add_argument(\n        \"--true_dir\", help=\"point to ground truth dir\", nargs=\"?\", default=\"/data3/zhangye/Tissue-Image-Segmentation-master/data/consep/test\", const=\"\"\n    )\n    parser.add_argument(\"--dataset\",)\n    args = parser.parse_args()\n    args.dataset = \"CryoNuSeg\"\n\n    if args.mode == \"instance\":\n        run_nuclei_inst_stat(args.pred_dir, args.true_dir, args.dataset, print_img_stats=False)\n    if args.mode == \"type\":\n        run_nuclei_type_stat(args.pred_dir, args.true_dir)\n"
        }
    ]
}